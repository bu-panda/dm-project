{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path = ['', '/Users/panda/miniconda2/lib/python27.zip',\n",
    "#            '/Users/panda/miniconda2/lib/python2.7', '/Users/panda/miniconda2/lib/python2.7/plat-darwin', \n",
    "#            '/Users/panda/miniconda2/lib/python2.7/plat-mac', \n",
    "#            '/Users/panda/miniconda2/lib/python2.7/plat-mac/lib-scriptpackages', \n",
    "#            '/Users/panda/miniconda2/lib/python2.7/lib-tk', '/Users/panda/miniconda2/lib/python2.7/lib-old', \n",
    "#            '/Users/panda/miniconda2/lib/python2.7/lib-dynload', '/Users/panda/miniconda2/lib/python2.7/site-packages', \n",
    "#            '/Users/panda/miniconda2/lib/python2.7/site-packages/setuptools-19.6.2-py2.7.egg']\n",
    "\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io import data\n",
    "from pandas import Series, DataFrame\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as linalg\n",
    "import scipy.cluster.hierarchy as hr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.svm as svm\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sklearn.datasets as sk_data\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import mixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.utils as utils\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "    \n",
    "import gmplot\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Station\n",
    "This is the class to aggregate data. Latter we will use its location information to draw our results on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Cluster is based on each station's information, so this class is the abstract of station.\n",
    "\n",
    "'''\n",
    "class Station(object):\n",
    "    \n",
    "    # @station_id int\n",
    "    # Use an integer number to initilize an station instance\n",
    "    def __init__(self, station_id):\n",
    "        self.station_id = station_id\n",
    "        self.features = ['TEMP', 'DEWP', 'SLP', 'STP',\n",
    "                         'VISIB','WDSP','MXSPD',\n",
    "                         'GUST','MAX','MIN','SNDP','FOG',\n",
    "                        'RAIN','SNOW','HAIL','THUNDER','TORNADO']\n",
    "        \n",
    "        self.missingValue = [9999.9, 9999.9, 9999.9, 9999.9,\n",
    "                            999.9, 999.9, 999.9,999.9,\n",
    "                             9999.9, 9999.9,999.9,\n",
    "                            -1,-1,-1,-1,-1,-1]\n",
    "        \n",
    "        self.META = {}\n",
    "        self.data = {}\n",
    "        self.location = [0.0,0.0]\n",
    "        \n",
    "        for x in xrange(1,13,1):\n",
    "            self.META[x] = {}\n",
    "            self.data[x] = {}\n",
    "            for name in self.features:\n",
    "            \n",
    "                self.META[x][name] = 0\n",
    "                self.data[x][name] = 0\n",
    "    \n",
    "        \n",
    "    \n",
    "    # @month int\n",
    "    # @data dict, must include all the fields that list in self.features\n",
    "    # This method will filt all the default or missing value\n",
    "    def inputData(self, month, data):\n",
    "        \n",
    "        for i in xrange(len(self.features)):\n",
    "            name = self.features[i]\n",
    "            \n",
    "            rs = data.get(name, None)\n",
    "            \n",
    "            if rs != None and rs != self.missingValue[i] :\n",
    "                self.data[month][name] += rs\n",
    "                self.META[month][name] += 1\n",
    "    \n",
    "    # @month int\n",
    "    # return the summary for each month. This is an inner function\n",
    "    def summaryByMonth(self, month):\n",
    "        exp = ['FOG','RAIN','SNOW','HAIL','THUNDER','TORNADO']\n",
    "        result = []\n",
    "        for kind in self.features:\n",
    "            \n",
    "            if kind in exp:\n",
    "                result.append(self.data[month][kind])\n",
    "            else:\n",
    "                v = 0.0\n",
    "                if self.META[month][kind] != 0:\n",
    "                    v = (self.data[month][kind]+0.0) / (self.META[month][kind])\n",
    "                result.append(v)\n",
    "        return result\n",
    "                    \n",
    "    \n",
    "    # For each station, this method return the summary.\n",
    "    # This method return the feature vector for analyzing\n",
    "    def summaryFeatureVector(self):\n",
    "        rs = []\n",
    "        for x in xrange(1,13,1):\n",
    "            rs.extend(self.summaryByMonth(x))\n",
    "        return rs\n",
    "    \n",
    "    # This method return method dictinary\n",
    "    def summaryByDict(self):\n",
    "        rs = {}\n",
    "        for x in xrange(1,13,1):\n",
    "            rs[x] = self.summaryByMonth(x)\n",
    "        return rs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Some of the data may contains one bit flag like '*,A,I' and so on\n",
    "# This method will pop this value if it contains one bit tag\n",
    "def extractNumber(s):\n",
    "    last = s[-1]\n",
    "    l = len(s)\n",
    "    if ord(last) >= ord('0') and ord(last) <= ord('9'):\n",
    "        return s\n",
    "    else:\n",
    "        return s[0:l-1]\n",
    "\n",
    "# 6 special weather are represented by 6-bits string in the raw data\n",
    "# Here I extract them and write the value to its coresponded field  \n",
    "def extractSpecialWeather(d, s):\n",
    "    w = ['FOG', 'RAIN', 'SNOW', 'HAIL', 'THUNDER', 'TORNADO']\n",
    "    if len(s) != 6 :\n",
    "        print 'alert! not well-formed data'\n",
    "    \n",
    "    for i in xrange(6):\n",
    "        if s[i] == '1':\n",
    "            d[w[i]] = 1\n",
    "        else:\n",
    "            d[w[i]] = 0\n",
    "    return d\n",
    "    \n",
    "# Input the joined data file path\n",
    "# Read line by line and build a dict with all stations\n",
    "def buildStationDict(filepath):\n",
    "    rs = {}\n",
    "    f = open(filepath)\n",
    "    names = ['TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', \n",
    "             'GUST', 'MAX', 'MIN', 'SNDP', 'FOG', 'RAIN', 'SNOW', 'HAIL', \n",
    "             'THUNDER', 'TORNADO']\n",
    "    for each in f:\n",
    "        data = each.strip().split(',')\n",
    "        station_id = int(data[0])\n",
    "        month = data[2][4:6]\n",
    "        month = int(month)\n",
    "        fdict = {}\n",
    "        i = 0\n",
    "        for x in xrange(3, 17, 2):\n",
    "            fdict[names[i]] = float(data[x])\n",
    "            i+=1\n",
    "        fdict['GUST'] = float(data[16])\n",
    "        \n",
    "        maxV = extractNumber(data[17])\n",
    "        minV = extractNumber(data[18])\n",
    "        \n",
    "        \n",
    "        fdict['MAX'] = float(maxV)\n",
    "        fdict['MIN'] = float(minV)\n",
    "        fdict['SNDP'] = float(data[20])\n",
    "        fdict = extractSpecialWeather(fdict, data[21])\n",
    "        \n",
    "        if rs.get(station_id) == None:\n",
    "            p = Station(station_id)\n",
    "            rs[station_id] = p\n",
    "        p = rs[station_id]\n",
    "        p.location = [data[-2],data[-1]]\n",
    "        p.inputData(month, fdict)\n",
    "    return rs\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "# Convert raw data location format\n",
    "# For the latitude and logitude, E,N will be positive while W,S will be negative\n",
    "def getLocation(loc):\n",
    "    rs = [0,0]\n",
    "    \n",
    "    la = loc[0]\n",
    "    lo = loc[1]\n",
    "    \n",
    "    end_la = la[-1]\n",
    "    end_lo = lo[-1]\n",
    "    \n",
    "    l1 = len(la)\n",
    "    l2 = len(lo)\n",
    "    \n",
    "    la = la[0:l1-1]\n",
    "    lo = lo[0: l2-1]\n",
    "    \n",
    "    if end_la == 'N':\n",
    "        rs[0] = float(la) / 100.0\n",
    "    else:\n",
    "        rs[0] = float(la) / -100.0\n",
    "    \n",
    "    if end_lo == 'E':\n",
    "        rs[1] = float(lo) / 100.0\n",
    "    else:\n",
    "        rs[1] = float(lo) / -100.0\n",
    "    return rs    \n",
    "    \n",
    "# @data pandas.DataFrame  Must contains 3 feilds, 'latitude','longitude','label'\n",
    "# @filepath str specify where you want to store the result\n",
    "# @colors, If you have more than 6 labels, you should specify your own color list\n",
    "def showOnMap(data, filepath,colors = []):\n",
    "    gmap = gmplot.GoogleMapPlotter(36.161517,-115.164011,16)\n",
    "\n",
    "    la = list(data['latitude'])\n",
    "    lo = list(data['longitude'])\n",
    "    label = list(data['label'])\n",
    "    \n",
    "    if len(colors) == 0:\n",
    "        colors = ['#ff0000','#00ff00','#0000ff','#ffff00','#ff00ff','#00ffff']\n",
    "    draw_la = collections.defaultdict(list)\n",
    "    draw_lo = collections.defaultdict(list)\n",
    "\n",
    "    kind = len(colors)\n",
    "    for i in range(len(label)):\n",
    "        try:\n",
    "            color = colors[int(label[i]) % kind]\n",
    "        \n",
    "            draw_la[color].append(la[i])\n",
    "            draw_lo[color].append(lo[i])\n",
    "        except:\n",
    "            print i\n",
    "            print label[i]\n",
    "\n",
    "    for each in draw_la.keys():\n",
    "        gmap.scatter(draw_la[each], draw_lo[each], each, size=10000, marker=False)\n",
    "    gmap.draw(filepath)   \n",
    "\n",
    "    \n",
    "# @data pandas.DataFrame\n",
    "# @n_clusters  How many clusters you want\n",
    "# @plot_graph Only to be True if you want to plot the graph, especially when there are only 2 labels\n",
    "def GMMCluster(data, n_clusters = 3, plot_graph = False):\n",
    "    colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "    print n_clusters\n",
    "    gmm = mixture.GMM(n_components=n_clusters, covariance_type='diag')\n",
    "    gmm.fit(data)\n",
    "    y_pred = gmm.predict(data)\n",
    "    \n",
    "    if plot_graph:   \n",
    "        plt.scatter(data[:, 0], data[:, 1], s=10,color=colors[y_pred].tolist(), alpha=0.8)\n",
    "        plt.show()\n",
    "    return y_pred\n",
    "\n",
    "'''\n",
    "data: ndarray. Data matrix\n",
    "n_clusters: int. How many clusters you want to have.\n",
    "detail: bool. Whether to out put some detail information\n",
    "plot_graph: bool. Whether to plot heat graph to compare unsorted and sorted label. \n",
    "\n",
    "return type (labels, centers)\n",
    "'''\n",
    "def kMeansCluster(data,clusters = 10, detail = False,plot_graph = False):\n",
    "    colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "    kmeans = KMeans(init='k-means++', n_clusters=clusters, n_init=10)\n",
    "    kmeans.fit_predict(data)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "    error = kmeans.inertia_\n",
    "    \n",
    "    if detail:\n",
    "        print \"The total error of the clustering is: \", error\n",
    "        print '\\nCluster labels'\n",
    "        print labels\n",
    "        print '\\n Cluster Centroids'\n",
    "        print centroids\n",
    "        \n",
    "    if plot_graph:\n",
    "        \n",
    "        plt.scatter(data[:, 0], data[:, 1], s=10,color=colors[labels].tolist(), alpha=0.8)\n",
    "        plt.show()\n",
    "        #idx = np.argsort(labels)\n",
    "        #rX = X[idx,:]\n",
    "        #fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,10))\n",
    "        #sns.heatmap( rX,xticklabels=False, yticklabels=False, linewidths=0,cbar=True,ax = ax1)\n",
    "        #sns.heatmap( X,xticklabels=False, yticklabels=False, linewidths=0,cbar=True,ax = ax2)\n",
    "    return (labels, centroids)\n",
    "\n",
    "'''\n",
    "data: ndarry. Data matrix\n",
    "begin: int. The beginning test number of cluster\n",
    "end: int. The maximum number of clusters\n",
    "'''\n",
    "def estimateCluster(data, end = 11):\n",
    "    error = np.zeros(end)\n",
    "    error[0] = 0;\n",
    "    for k in range(1,end):\n",
    "        kmeans = KMeans(init='k-means++', n_clusters=k, n_init=10)\n",
    "        kmeans.fit_predict(data)\n",
    "        error[k] = kmeans.inertia_\n",
    "\n",
    "    plt.plot(range(1,len(error)),error[1:])\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the station dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = buildStationDict('data_with_location.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert station to feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "locations = []    \n",
    "\n",
    "for station_id in m.keys():    \n",
    "    station = m[station_id]\n",
    "    locations.append( getLocation( station.location) )\n",
    "    features.append(station.summaryFeatureVector())\n",
    "    \n",
    "\n",
    "data = np.array(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do GMM cluster\n",
    "Do GMM cluster and show it on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "labels = GMMCluster(data, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'label', u'latitude', u'longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "las = []\n",
    "los = []\n",
    "label = []\n",
    "i = 0\n",
    "for each in locations:\n",
    "    las.append(each[0])\n",
    "    los.append(each[1])\n",
    "    label.append(labels[i])\n",
    "    i+=1\n",
    "\n",
    "rs = {'latitude':las, 'longitude':los, 'label':label}\n",
    "\n",
    "df = pd.DataFrame(rs)\n",
    "\n",
    "print df.columns\n",
    "\n",
    "colors = ['#000000','#0000FF','#8A2BE2',\n",
    "          '#5F9EA0','#7FFF00','#FF7F50',\n",
    "          '#DC143C', '#00FFFF','#006400',\n",
    "         '#8B008B', '#556B2F','#483D8B',\n",
    "         '#9400D3','#FFD700','#FF4500']\n",
    "\n",
    "    \n",
    "\n",
    "showOnMap(df, 'GMM-cluster.html',colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Next part SVM\n",
    "\n",
    "- First part is the helper functions\n",
    "- Use SVM to predict special weather\n",
    "- Draw ROC curve to show our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# @weather_str 6-bits string. \n",
    "# @in_detail if True, return lables from 0 to 63. If False, return boolean labels\n",
    "def getSpecialWeatherLabel(weather_str, in_detail = False):\n",
    "    \n",
    "    label = 0\n",
    "    for x in range(6):\n",
    "        weight = 1 << x\n",
    "        v = int(weather_str[x])\n",
    "        label += weight*v\n",
    "    \n",
    "    if in_detail:\n",
    "        return label\n",
    "    else:\n",
    "        return label == 0\n",
    "        \n",
    "\n",
    "# For each row in the file, get its features and labels\n",
    "# @filepath input data file path\n",
    "# @return type: pandas.DataFrame\n",
    "def extractClassificationTable(filepath):\n",
    "    f = open(filepath)\n",
    "    \n",
    "    fdict = collections.defaultdict(list)\n",
    "    \n",
    "    names = ['TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', \n",
    "             'GUST', 'MAX', 'MIN', 'SNDP', 'FOG', 'RAIN', 'SNOW', 'HAIL', \n",
    "             'THUNDER', 'TORNADO']\n",
    "    for each in f:\n",
    "        data = each.strip().split(',')\n",
    "        #get month\n",
    "        month = data[2][4:6]\n",
    "        month = int(month)\n",
    "        \n",
    "        fdict['MONTH'].append(month)\n",
    "        \n",
    "        i = 0\n",
    "        for x in xrange(3, 17, 2):\n",
    "            fdict[names[i]].append(float(data[x]))\n",
    "            i+=1\n",
    "        fdict['GUST'].append(float(data[16]))\n",
    "        \n",
    "        maxV = extractNumber(data[17])\n",
    "        minV = extractNumber(data[18])\n",
    "        \n",
    "        \n",
    "        fdict['MAX'].append(float(maxV))\n",
    "        fdict['MIN'].append(float(minV))\n",
    "        fdict['SNDP'].append(float(data[20]))\n",
    "        fdict['LABEL'].append(getSpecialWeatherLabel(data[21], False))\n",
    "        \n",
    "        lati, logi = getLocation([data[-2],data[-1]])\n",
    "        fdict['LAT'].append(lati)\n",
    "        fdict['LOG'].append(logi)\n",
    "    \n",
    "    frame = pd.DataFrame(fdict)\n",
    "    \n",
    "    return frame\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "f = open('data_with_location.csv')\n",
    "fin = open('data_narrow.csv','w')\n",
    "\n",
    "for each in f:\n",
    "    i = random.random()\n",
    "    if i < 0.01:\n",
    "        fin.write(each)\n",
    "\n",
    "f.close()\n",
    "fin.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23260, 14)\n",
      "   DEWP   GUST    LAT  LOG   MAX   MIN  MONTH  MXSPD     SLP   SNDP     STP  \\\n",
      "0  44.3  999.9  70.56 -8.4  46.9  45.0      8   11.7  1011.2  999.9  1010.1   \n",
      "1  39.9  999.9  70.56 -8.4  44.1  36.9     10   21.4   997.6  999.9   996.5   \n",
      "\n",
      "   TEMP  VISIB  WDSP  \n",
      "0  45.9    4.8   9.0  \n",
      "1  41.6    1.4   8.9  \n",
      "Index([u'DEWP', u'GUST', u'LAT', u'LOG', u'MAX', u'MIN', u'MONTH', u'MXSPD',\n",
      "       u'SLP', u'SNDP', u'STP', u'TEMP', u'VISIB', u'WDSP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "classify_dataframe = extractClassificationTable('data_narrow.csv')\n",
    "weather_labels  =classify_dataframe.pop('LABEL')\n",
    "print classify_dataframe.shape\n",
    "print classify_dataframe.head(2)\n",
    "print classify_dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset to train and test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23260L, 14L)\n",
      "(23260L,)\n",
      "[ True  True  True ...,  True  True  True]\n",
      "(5000L, 14L) (5000L,)\n",
      "(18260L, 14L) (18260L,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = weather_labels.values\n",
    "X = classify_dataframe.values\n",
    "\n",
    "X, y = utils.shuffle(X, y, random_state=1)\n",
    "print X.shape\n",
    "print y.shape\n",
    "print y\n",
    "train_set_size = 5000\n",
    "X_train = X[:train_set_size]  # selects first 10000 rows (examples) for train set\n",
    "y_train = y[:train_set_size]\n",
    "X_test = X[train_set_size:]   # selects from row 10000 until the last one for test set\n",
    "y_test = y[train_set_size:]\n",
    "print(X_train.shape), y_train.shape\n",
    "print(X_test.shape), y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do SVM classification and show its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM test set: 0.519003285871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himani\\Anaconda2\\lib\\site-packages\\scikit_learn-0.17.1-py2.7-win-amd64.egg\\sklearn\\svm\\base.py:224: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "svc = svm.SVC(kernel='linear', max_iter=10000)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_test = svc.predict(X_test)\n",
    "print \"Accuracy of SVM test set:\", svc.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve to evaluate our result\n",
    "When you try to plot ROC curve, make sure your label is binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11630L, 1L)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4a67dba11571>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "classifier = OneVsRestClassifier(svc)\n",
    "\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "print y_score.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2057f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:], y_score[:])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr[1], tpr[1], label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
